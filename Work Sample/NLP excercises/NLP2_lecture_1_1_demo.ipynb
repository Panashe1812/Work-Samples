{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP2 Lecture 1 Support Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "<p>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#Mean-Reciprocal-Rank-(MRR)\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "        Mean Reciprocal Rank (MRR)\n",
    "    </a>\n",
    "</div>\n",
    "</div>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#Mean-Average-Precision-(MAP)\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "        Mean Average Precision (MAP)\n",
    "    </a>\n",
    "</div>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#Text-Generation-with-RNN\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "        Text Generation with RNN\n",
    "    </a>\n",
    "</div>\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#Building-an-Attention-Model\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>\n",
    "        Building an Attention Model\n",
    "    </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-Reciprocal-Rank-(MRR)\n",
    "Mean reciprocal rank (MRR) gives you a general measure of quality in these situations, but MRR only cares about the single highest-ranked relevant item. If your system returns a relevant item in the third-highest spot, that's what MRR cares about. It doesn't care if the other relevant items (assuming there are any) are ranked number 4 or number 20.<br/>\n",
    "Therefore, MRR is appropriate to judge a system where either (a) there's only one relevant result, or (b) in your use-case you only really care about the highest-ranked one. This might be true in some web-search scenarios, for example, where the user just wants to find one thing to click on, they don't need any more. (Though is that typically true, or would you be more happy with a web search that returned ten pretty good answers, and you could make your own judgment about which of those to click on...?) <br/>\n",
    "\n",
    "ref. https://stats.stackexchange.com/questions/127041/mean-average-precision-vs-mean-reciprocal-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Information Retrieval metrics\n",
    "Useful Resources:\n",
    "http://www.cs.utexas.edu/~mooney/ir-course/slides/Evaluation.ppt\n",
    "http://www.nii.ac.jp/TechReports/05-014E.pdf\n",
    "http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "http://hal.archives-ouvertes.fr/docs/00/72/67/60/PDF/07-busa-fekete.pdf\n",
    "Learning to Rank for Information Retrieval (Tie-Yan Liu)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(rs):\n",
    "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.61111111111111105\n",
    "    >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.5\n",
    "    >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.75\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean reciprocal rank\n",
    "    \"\"\"\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "mean_reciprocal_rank(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "mean_reciprocal_rank(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "mean_reciprocal_rank(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Example.  Return to Slides\n",
    "\n",
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)\n",
    "\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#NLP2-Lecture-1-Support-Notebook\">\n",
    "        <span class=\"toc-item-num\">&nbsp;&nbsp;</span>\n",
    "        Go to TOP\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-Average-Precision-(MAP)\n",
    "It considers whether all of the relevant items tend to get ranked highly. So in the top-20 example, it doesn't only care if there's a relevant answer up at number 3, it also cares whether all the \"yes\" items in that list are bunched up towards the top.\n",
    "\n",
    "There's no real need to use MAP if you only ever have 1 relevant answer in your data, MRR would be fine. But if you submit a query such as \"female heads of state\" and the top three results are \"Margaret Thatcher\", \"Vigdís Finnbogadóttir\", and \"Pratibha Patil\", those all are distinct but correct answers, and we might want to judge this as a good result, better than a system which only floated one of those answers to the top <br/>\n",
    "\n",
    "Below we have the functions to implement that: precision_at_k, average_precision and mean_average_precision.\n",
    "\n",
    "ref. https://stats.stackexchange.com/questions/127041/mean-average-precision-vs-mean-reciprocal-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(r, k):\n",
    "    \"\"\"Score is precision @ k\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> precision_at_k(r, 1)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 2)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 3)\n",
    "    0.33333333333333331\n",
    "    >>> precision_at_k(r, 4)\n",
    "    Traceback (most recent call last):\n",
    "        File \"<stdin>\", line 1, in ?\n",
    "    ValueError: Relevance score length < k\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Precision @ k\n",
    "    Raises:\n",
    "        ValueError: len(r) must be >= k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(r):\n",
    "    \"\"\"Score is average precision (area under PR curve)\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "    >>> delta_r = 1. / sum(r)\n",
    "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
    "    0.7833333333333333\n",
    "    >>> average_precision(r)\n",
    "    0.78333333333333333\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Average precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(rs):\n",
    "    \"\"\"Score is mean average precision\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.78333333333333333\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.39166666666666666\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean average precision\n",
    "    \"\"\"\n",
    "    return np.mean([average_precision(r) for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "mean_average_precision(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
    "mean_average_precision(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Example.  Return to Slides\n",
    "\n",
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)\n",
    "\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#NLP2-Lecture-1-Support-Notebook\">\n",
    "        <span class=\"toc-item-num\">&nbsp;&nbsp;</span>\n",
    "        Go to TOP\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation with RNN\n",
    "In this section we implement a language model introduced in :numref:`chap_rnn` from scratch. It is based on a character-level recurrent neural network trained on H. G. Wells' *The Time Machine*. As before, we start by reading the dataset first, which is introduced in :numref:`sec_language_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/d2l-ai/d2l-en@v0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[device(type='cpu')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2l.try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding\n",
    "\n",
    "Remember that each token is presented as a numerical index in `train_iter`.\n",
    "Feeding these indices directly to the neural network might make it hard to\n",
    "learn. We often present each token as a more expressive feature vector. The\n",
    "easiest representation is called *one-hot encoding*.\n",
    "\n",
    "In a nutshell, we map each index to a different unit vector: assume that the number of different tokens in the vocabulary is $N$ (the `len(vocab)`) and the token indices range from 0 to $N-1$. If the index of a token is the integer $i$, then we create a vector $\\mathbf{e}_i$ of all 0s with a length of $N$ and set the element at position $i$ to 1. This vector is the one-hot vector of the original token. The one-hot vectors with indices 0 and 2 are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the minibatch we sample each time is (batch size, timestep). The `one_hot` function transforms such a minibatch into a 3-D tensor with the last dimension equals to the vocabulary size. We often transpose the input so that we will obtain a (timestep, batch size, vocabulary size) output that fits into a sequence model easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Model Parameters\n",
    "\n",
    "Next, we initialize the model parameters for a RNN model. The number of hidden units `num_hiddens` is a tunable parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # Hidden layer parameters\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # Output layer parameters\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # Attach gradients\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model\n",
    "\n",
    "First, we need an `init_rnn_state` function to return the hidden state at initialization. It returns an `ndarray` filled with 0 and with a shape of (batch size, number of hidden units). Using tuples makes it easier to handle situations where the hidden state contains multiple variables (e.g., when combining multiple layers in an RNN where each layer requires initializing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `rnn` function defines how to compute the hidden state and output\n",
    "in a timestep. The activation function here uses the $\\tanh$ function. As\n",
    "described in :numref:`sec_mlp`, the\n",
    "mean value of the $\\tanh$ function is 0, when the elements are evenly\n",
    "distributed over the real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # Here `inputs` shape: (`num_steps`, `batch_size`, `vocab_size`)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # Shape of `X`: (`batch_size`, `vocab_size`)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all functions defined, next we create a class to wrap these functions and store parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "\n",
    "class RNNModelScratch: #@save\n",
    "    \"\"\"A RNN Model implemented from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a sanity check whether inputs and outputs have the correct dimensions, e.g., to ensure that the dimensionality of the hidden state has not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.98 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output shape is (number steps $\\times$ batch size, vocabulary size), while the hidden state shape remains the same, i.e., (batch size, number of hidden units).\n",
    "\n",
    "## Prediction\n",
    "\n",
    "We first explain the predicting function so we can regularly check the prediction during training. This function predicts the next `num_predicts` characters based on the `prefix` (a string containing several characters). For the beginning of the sequence, we only update the hidden state. After that we begin generating new characters and emitting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"Generate new characters following the `prefix`.\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape(\n",
    "        (1, 1))\n",
    "    for y in prefix[1:]:  # Warm-up period\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # Predict `num_preds` steps\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the `predict_rnn` function first. Given that we did not train the network, it will generate nonsensical predictions. We initialize it with the sequence `traveller ` and have it generate 10 additional characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller pbhvk pbhv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "\n",
    "For a sequence of length $T$, we compute the gradients over these $T$ timesteps in an iteration, which results in a chain of matrix-products with length  $\\mathcal{O}(T)$ during backpropagating. As mentioned in :numref:`sec_numerical_stability`, it might result in numerical instability, e.g., the gradients may either explode or vanish, when $T$ is large. Therefore, RNN models often need extra help to stabilize the training.\n",
    "\n",
    "Recall that when solving an optimization problem, we take update steps for the weights $\\mathbf{w}$ in the general direction of the negative gradient $\\mathbf{g}_t$ on a minibatch, say $\\mathbf{w} - \\eta \\cdot \\mathbf{g}_t$. Let's further assume that the objective is well behaved, i.e., it is Lipschitz continuous with constant $L$, i.e.,\n",
    "\n",
    "$$|l(\\mathbf{w}) - l(\\mathbf{w}')| \\leq L \\|\\mathbf{w} - \\mathbf{w}'\\|.$$\n",
    "\n",
    "In this case we can safely assume that if we update the weight vector by $\\eta \\cdot \\mathbf{g}_t$, we will not observe a change by more than $L \\eta \\|\\mathbf{g}_t\\|$. This is both a curse and a blessing. A curse since it limits the speed of making progress, whereas a blessing since it limits the extent to which things can go wrong if we move in the wrong direction.\n",
    "\n",
    "Sometimes the gradients can be quite large and the optimization algorithm may fail to converge. We could address this by reducing the learning rate $\\eta$ or by some other higher order trick. But what if we only rarely get large gradients? In this case such an approach may appear entirely unwarranted. One alternative is to clip the gradients by projecting them back to a ball of a given radius, say $\\theta$ via\n",
    "\n",
    "$$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}.$$\n",
    "\n",
    "By doing so we know that the gradient norm never exceeds $\\theta$ and that the\n",
    "updated gradient is entirely aligned with the original direction $\\mathbf{g}$.\n",
    "It also has the desirable side-effect of limiting the influence any given\n",
    "minibatch (and within it any given sample) can exert on the weight vectors. This\n",
    "bestows a certain degree of robustness to the model. Gradient clipping provides\n",
    "a quick fix to the gradient exploding. While it does not entirely solve the problem, it is one of the many techniques to alleviate it.\n",
    "\n",
    "Below we define a function to clip the gradients of a model that is either a `RNNModelScratch` instance or a Gluon model. Also note that we compute the gradient norm over all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Let's first define the function to train the model on one data epoch. It differs from the models training of :numref:`sec_softmax_scratch` in three places:\n",
    "\n",
    "1. Different sampling methods for sequential data (independent sampling and\n",
    "   sequential partitioning) will result in differences in the initialization of\n",
    "   hidden states.\n",
    "1. We clip the gradients before updating the model parameters. This ensures that the model does not diverge even when gradients blow up at some point during the training process, and it effectively reduces the step size automatically.\n",
    "1. We use perplexity to evaluate the model. This ensures that sequences of different length are comparable.\n",
    "\n",
    "\n",
    "When the consecutive sampling is used, we initialize the hidden state at the beginning of each epoch. Since the $i^\\mathrm{th}$ example in the next minibatch is adjacent to the current $i^\\mathrm{th}$ example, so the next minibatch can use the current hidden state directly, we only detach the gradient so that we compute the gradients within a minibatch. When using the random sampling, we need to re-initialize the hidden state for each iteration since each example is sampled with a random position. Same as the `train_epoch_ch3` function in :numref:`sec_softmax_scratch`, we use generalized `updater`, which could be either a Gluon trainer or a scratched implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"Train a net within one epoch (defined in Chapter 8).\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # Initialize `state` when either it is the first iteration or\n",
    "            # using random sampling\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # `state` is a tensor for `nn.GRU`\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # `state` is a tuple of tensors for `nn.LSTM` and\n",
    "                # for our custom scratch implementation\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # Since the `mean` function has been invoked\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training function again supports either we implement the model from scratch or using Gluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"Train a model (defined in Chapter 8).\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    \n",
    "    # Initialize\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n",
    "    \n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    \n",
    "    # Train and predict\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'perplexity {ppl:.1f}, {speed:.1f} tokens/sec on {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a model. Since we only use $10,000$ tokens in the dataset, the model needs more epochs to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity 1.0, 15502.0 tokens/sec on cpu\n",
      "time travelleryou can show black is white by argument said filby\n",
      "travelleryou can show black is white by argument said filby\n",
      "Wall time: 5min 20s\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 262.1875 180.65625\" width=\"262.1875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2022-01-05T10:59:38.082263</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 180.65625 \r\n",
       "L 262.1875 180.65625 \r\n",
       "L 262.1875 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 50.14375 143.1 \r\n",
       "L 245.44375 143.1 \r\n",
       "L 245.44375 7.2 \r\n",
       "L 50.14375 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 86.015179 143.1 \r\n",
       "L 86.015179 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m598165b234\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.015179\" xlink:href=\"#m598165b234\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 100 -->\r\n",
       "      <g transform=\"translate(76.471429 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "        <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 125.872321 143.1 \r\n",
       "L 125.872321 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"125.872321\" xlink:href=\"#m598165b234\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 200 -->\r\n",
       "      <g transform=\"translate(116.328571 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 165.729464 143.1 \r\n",
       "L 165.729464 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.729464\" xlink:href=\"#m598165b234\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 300 -->\r\n",
       "      <g transform=\"translate(156.185714 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 40.578125 39.3125 \r\n",
       "Q 47.65625 37.796875 51.625 33 \r\n",
       "Q 55.609375 28.21875 55.609375 21.1875 \r\n",
       "Q 55.609375 10.40625 48.1875 4.484375 \r\n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \r\n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \r\n",
       "Q 12.796875 0.390625 7.625 2.203125 \r\n",
       "L 7.625 11.71875 \r\n",
       "Q 11.71875 9.328125 16.59375 8.109375 \r\n",
       "Q 21.484375 6.890625 26.8125 6.890625 \r\n",
       "Q 36.078125 6.890625 40.9375 10.546875 \r\n",
       "Q 45.796875 14.203125 45.796875 21.1875 \r\n",
       "Q 45.796875 27.640625 41.28125 31.265625 \r\n",
       "Q 36.765625 34.90625 28.71875 34.90625 \r\n",
       "L 20.21875 34.90625 \r\n",
       "L 20.21875 43.015625 \r\n",
       "L 29.109375 43.015625 \r\n",
       "Q 36.375 43.015625 40.234375 45.921875 \r\n",
       "Q 44.09375 48.828125 44.09375 54.296875 \r\n",
       "Q 44.09375 59.90625 40.109375 62.90625 \r\n",
       "Q 36.140625 65.921875 28.71875 65.921875 \r\n",
       "Q 24.65625 65.921875 20.015625 65.03125 \r\n",
       "Q 15.375 64.15625 9.8125 62.3125 \r\n",
       "L 9.8125 71.09375 \r\n",
       "Q 15.4375 72.65625 20.34375 73.4375 \r\n",
       "Q 25.25 74.21875 29.59375 74.21875 \r\n",
       "Q 40.828125 74.21875 47.359375 69.109375 \r\n",
       "Q 53.90625 64.015625 53.90625 55.328125 \r\n",
       "Q 53.90625 49.265625 50.4375 45.09375 \r\n",
       "Q 46.96875 40.921875 40.578125 39.3125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 205.586607 143.1 \r\n",
       "L 205.586607 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.586607\" xlink:href=\"#m598165b234\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 400 -->\r\n",
       "      <g transform=\"translate(196.042857 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 245.44375 143.1 \r\n",
       "L 245.44375 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.44375\" xlink:href=\"#m598165b234\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 500 -->\r\n",
       "      <g transform=\"translate(235.9 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 10.796875 72.90625 \r\n",
       "L 49.515625 72.90625 \r\n",
       "L 49.515625 64.59375 \r\n",
       "L 19.828125 64.59375 \r\n",
       "L 19.828125 46.734375 \r\n",
       "Q 21.96875 47.46875 24.109375 47.828125 \r\n",
       "Q 26.265625 48.1875 28.421875 48.1875 \r\n",
       "Q 40.625 48.1875 47.75 41.5 \r\n",
       "Q 54.890625 34.8125 54.890625 23.390625 \r\n",
       "Q 54.890625 11.625 47.5625 5.09375 \r\n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \r\n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \r\n",
       "Q 12.796875 0.140625 7.71875 1.703125 \r\n",
       "L 7.71875 11.625 \r\n",
       "Q 12.109375 9.234375 16.796875 8.0625 \r\n",
       "Q 21.484375 6.890625 26.703125 6.890625 \r\n",
       "Q 35.15625 6.890625 40.078125 11.328125 \r\n",
       "Q 45.015625 15.765625 45.015625 23.390625 \r\n",
       "Q 45.015625 31 40.078125 35.4375 \r\n",
       "Q 35.15625 39.890625 26.703125 39.890625 \r\n",
       "Q 22.75 39.890625 18.8125 39.015625 \r\n",
       "Q 14.890625 38.140625 10.796875 36.28125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_6\">\r\n",
       "     <!-- epoch -->\r\n",
       "     <g transform=\"translate(132.565625 171.376563)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 56.203125 29.59375 \r\n",
       "L 56.203125 25.203125 \r\n",
       "L 14.890625 25.203125 \r\n",
       "Q 15.484375 15.921875 20.484375 11.0625 \r\n",
       "Q 25.484375 6.203125 34.421875 6.203125 \r\n",
       "Q 39.59375 6.203125 44.453125 7.46875 \r\n",
       "Q 49.3125 8.734375 54.109375 11.28125 \r\n",
       "L 54.109375 2.78125 \r\n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \r\n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \r\n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \r\n",
       "Q 5.515625 13.8125 5.515625 26.8125 \r\n",
       "Q 5.515625 40.234375 12.765625 48.109375 \r\n",
       "Q 20.015625 56 32.328125 56 \r\n",
       "Q 43.359375 56 49.78125 48.890625 \r\n",
       "Q 56.203125 41.796875 56.203125 29.59375 \r\n",
       "z\r\n",
       "M 47.21875 32.234375 \r\n",
       "Q 47.125 39.59375 43.09375 43.984375 \r\n",
       "Q 39.0625 48.390625 32.421875 48.390625 \r\n",
       "Q 24.90625 48.390625 20.390625 44.140625 \r\n",
       "Q 15.875 39.890625 15.1875 32.171875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-101\"/>\r\n",
       "       <path d=\"M 18.109375 8.203125 \r\n",
       "L 18.109375 -20.796875 \r\n",
       "L 9.078125 -20.796875 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.390625 \r\n",
       "Q 20.953125 51.265625 25.265625 53.625 \r\n",
       "Q 29.59375 56 35.59375 56 \r\n",
       "Q 45.5625 56 51.78125 48.09375 \r\n",
       "Q 58.015625 40.1875 58.015625 27.296875 \r\n",
       "Q 58.015625 14.40625 51.78125 6.484375 \r\n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \r\n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \r\n",
       "Q 20.953125 3.328125 18.109375 8.203125 \r\n",
       "z\r\n",
       "M 48.6875 27.296875 \r\n",
       "Q 48.6875 37.203125 44.609375 42.84375 \r\n",
       "Q 40.53125 48.484375 33.40625 48.484375 \r\n",
       "Q 26.265625 48.484375 22.1875 42.84375 \r\n",
       "Q 18.109375 37.203125 18.109375 27.296875 \r\n",
       "Q 18.109375 17.390625 22.1875 11.75 \r\n",
       "Q 26.265625 6.109375 33.40625 6.109375 \r\n",
       "Q 40.53125 6.109375 44.609375 11.75 \r\n",
       "Q 48.6875 17.390625 48.6875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-112\"/>\r\n",
       "       <path d=\"M 30.609375 48.390625 \r\n",
       "Q 23.390625 48.390625 19.1875 42.75 \r\n",
       "Q 14.984375 37.109375 14.984375 27.296875 \r\n",
       "Q 14.984375 17.484375 19.15625 11.84375 \r\n",
       "Q 23.34375 6.203125 30.609375 6.203125 \r\n",
       "Q 37.796875 6.203125 41.984375 11.859375 \r\n",
       "Q 46.1875 17.53125 46.1875 27.296875 \r\n",
       "Q 46.1875 37.015625 41.984375 42.703125 \r\n",
       "Q 37.796875 48.390625 30.609375 48.390625 \r\n",
       "z\r\n",
       "M 30.609375 56 \r\n",
       "Q 42.328125 56 49.015625 48.375 \r\n",
       "Q 55.71875 40.765625 55.71875 27.296875 \r\n",
       "Q 55.71875 13.875 49.015625 6.21875 \r\n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \r\n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \r\n",
       "Q 5.515625 13.875 5.515625 27.296875 \r\n",
       "Q 5.515625 40.765625 12.171875 48.375 \r\n",
       "Q 18.84375 56 30.609375 56 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-111\"/>\r\n",
       "       <path d=\"M 48.78125 52.59375 \r\n",
       "L 48.78125 44.1875 \r\n",
       "Q 44.96875 46.296875 41.140625 47.34375 \r\n",
       "Q 37.3125 48.390625 33.40625 48.390625 \r\n",
       "Q 24.65625 48.390625 19.8125 42.84375 \r\n",
       "Q 14.984375 37.3125 14.984375 27.296875 \r\n",
       "Q 14.984375 17.28125 19.8125 11.734375 \r\n",
       "Q 24.65625 6.203125 33.40625 6.203125 \r\n",
       "Q 37.3125 6.203125 41.140625 7.25 \r\n",
       "Q 44.96875 8.296875 48.78125 10.40625 \r\n",
       "L 48.78125 2.09375 \r\n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \r\n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \r\n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \r\n",
       "Q 5.515625 14.109375 5.515625 27.296875 \r\n",
       "Q 5.515625 40.671875 12.859375 48.328125 \r\n",
       "Q 20.21875 56 33.015625 56 \r\n",
       "Q 37.15625 56 41.109375 55.140625 \r\n",
       "Q 45.0625 54.296875 48.78125 52.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-99\"/>\r\n",
       "       <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 75.984375 \r\n",
       "L 18.109375 75.984375 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-104\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 50.14375 122.409655 \r\n",
       "L 245.44375 122.409655 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"mda02b25e39\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mda02b25e39\" y=\"122.409655\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 2.5 -->\r\n",
       "      <g transform=\"translate(27.240625 126.208874)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 10.6875 12.40625 \r\n",
       "L 21 12.40625 \r\n",
       "L 21 0 \r\n",
       "L 10.6875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-46\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 50.14375 97.900727 \r\n",
       "L 245.44375 97.900727 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_14\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mda02b25e39\" y=\"97.900727\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 5.0 -->\r\n",
       "      <g transform=\"translate(27.240625 101.699946)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_15\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 50.14375 73.391799 \r\n",
       "L 245.44375 73.391799 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_16\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mda02b25e39\" y=\"73.391799\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 7.5 -->\r\n",
       "      <g transform=\"translate(27.240625 77.191018)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 8.203125 72.90625 \r\n",
       "L 55.078125 72.90625 \r\n",
       "L 55.078125 68.703125 \r\n",
       "L 28.609375 0 \r\n",
       "L 18.3125 0 \r\n",
       "L 43.21875 64.59375 \r\n",
       "L 8.203125 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-55\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_17\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 50.14375 48.882871 \r\n",
       "L 245.44375 48.882871 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_18\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mda02b25e39\" y=\"48.882871\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 10.0 -->\r\n",
       "      <g transform=\"translate(20.878125 52.68209)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_19\">\r\n",
       "      <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 50.14375 24.373943 \r\n",
       "L 245.44375 24.373943 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_20\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#mda02b25e39\" y=\"24.373943\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 12.5 -->\r\n",
       "      <g transform=\"translate(20.878125 28.173162)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_12\">\r\n",
       "     <!-- perplexity -->\r\n",
       "     <g transform=\"translate(14.798437 100.276562)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 41.109375 46.296875 \r\n",
       "Q 39.59375 47.171875 37.8125 47.578125 \r\n",
       "Q 36.03125 48 33.890625 48 \r\n",
       "Q 26.265625 48 22.1875 43.046875 \r\n",
       "Q 18.109375 38.09375 18.109375 28.8125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 20.953125 51.171875 25.484375 53.578125 \r\n",
       "Q 30.03125 56 36.53125 56 \r\n",
       "Q 37.453125 56 38.578125 55.875 \r\n",
       "Q 39.703125 55.765625 41.0625 55.515625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-114\"/>\r\n",
       "       <path d=\"M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-108\"/>\r\n",
       "       <path d=\"M 54.890625 54.6875 \r\n",
       "L 35.109375 28.078125 \r\n",
       "L 55.90625 0 \r\n",
       "L 45.3125 0 \r\n",
       "L 29.390625 21.484375 \r\n",
       "L 13.484375 0 \r\n",
       "L 2.875 0 \r\n",
       "L 24.125 28.609375 \r\n",
       "L 4.6875 54.6875 \r\n",
       "L 15.28125 54.6875 \r\n",
       "L 29.78125 35.203125 \r\n",
       "L 44.28125 54.6875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-120\"/>\r\n",
       "       <path d=\"M 9.421875 54.6875 \r\n",
       "L 18.40625 54.6875 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 64.59375 \r\n",
       "L 9.421875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-105\"/>\r\n",
       "       <path d=\"M 18.3125 70.21875 \r\n",
       "L 18.3125 54.6875 \r\n",
       "L 36.8125 54.6875 \r\n",
       "L 36.8125 47.703125 \r\n",
       "L 18.3125 47.703125 \r\n",
       "L 18.3125 18.015625 \r\n",
       "Q 18.3125 11.328125 20.140625 9.421875 \r\n",
       "Q 21.96875 7.515625 27.59375 7.515625 \r\n",
       "L 36.8125 7.515625 \r\n",
       "L 36.8125 0 \r\n",
       "L 27.59375 0 \r\n",
       "Q 17.1875 0 13.234375 3.875 \r\n",
       "Q 9.28125 7.765625 9.28125 18.015625 \r\n",
       "L 9.28125 47.703125 \r\n",
       "L 2.6875 47.703125 \r\n",
       "L 2.6875 54.6875 \r\n",
       "L 9.28125 54.6875 \r\n",
       "L 9.28125 70.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-116\"/>\r\n",
       "       <path d=\"M 32.171875 -5.078125 \r\n",
       "Q 28.375 -14.84375 24.75 -17.8125 \r\n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \r\n",
       "L 7.90625 -20.796875 \r\n",
       "L 7.90625 -13.28125 \r\n",
       "L 13.1875 -13.28125 \r\n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \r\n",
       "Q 21 -9.765625 23.484375 -3.21875 \r\n",
       "L 25.09375 0.875 \r\n",
       "L 2.984375 54.6875 \r\n",
       "L 12.5 54.6875 \r\n",
       "L 29.59375 11.921875 \r\n",
       "L 46.6875 54.6875 \r\n",
       "L 56.203125 54.6875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-121\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"166.113281\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"229.589844\" xlink:href=\"#DejaVuSans-108\"/>\r\n",
       "      <use x=\"257.373047\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"317.146484\" xlink:href=\"#DejaVuSans-120\"/>\r\n",
       "      <use x=\"376.326172\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"404.109375\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"443.318359\" xlink:href=\"#DejaVuSans-121\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_21\">\r\n",
       "    <path clip-path=\"url(#pdc7cf36ab0)\" d=\"M 50.14375 13.377273 \r\n",
       "L 54.129464 43.554421 \r\n",
       "L 58.115179 52.235018 \r\n",
       "L 62.100893 57.425259 \r\n",
       "L 66.086607 62.663642 \r\n",
       "L 70.072321 66.286978 \r\n",
       "L 74.058036 67.445701 \r\n",
       "L 78.04375 70.092075 \r\n",
       "L 82.029464 71.904061 \r\n",
       "L 86.015179 74.321624 \r\n",
       "L 90.000893 75.797146 \r\n",
       "L 93.986607 79.553688 \r\n",
       "L 97.972321 83.154198 \r\n",
       "L 101.958036 86.310044 \r\n",
       "L 105.94375 90.108089 \r\n",
       "L 109.929464 93.092306 \r\n",
       "L 113.915179 98.772937 \r\n",
       "L 117.900893 106.713578 \r\n",
       "L 121.886607 111.56058 \r\n",
       "L 125.872321 116.994938 \r\n",
       "L 129.858036 121.328236 \r\n",
       "L 133.84375 124.359631 \r\n",
       "L 137.829464 127.766788 \r\n",
       "L 141.815179 129.297813 \r\n",
       "L 145.800893 131.054759 \r\n",
       "L 149.786607 132.149192 \r\n",
       "L 153.772321 133.217082 \r\n",
       "L 157.758036 133.441882 \r\n",
       "L 161.74375 133.941669 \r\n",
       "L 165.729464 134.015564 \r\n",
       "L 169.715179 134.936069 \r\n",
       "L 173.700893 135.751013 \r\n",
       "L 177.686607 135.733286 \r\n",
       "L 181.672321 136.133502 \r\n",
       "L 185.658036 135.257645 \r\n",
       "L 189.64375 136.015132 \r\n",
       "L 193.629464 136.403757 \r\n",
       "L 197.615179 136.45162 \r\n",
       "L 201.600893 136.405335 \r\n",
       "L 205.586607 136.532471 \r\n",
       "L 209.572321 136.67541 \r\n",
       "L 213.558036 136.842303 \r\n",
       "L 217.54375 136.733559 \r\n",
       "L 221.529464 136.684339 \r\n",
       "L 225.515179 136.629838 \r\n",
       "L 229.500893 136.871793 \r\n",
       "L 233.486607 136.734255 \r\n",
       "L 237.472321 136.707223 \r\n",
       "L 241.458036 136.922727 \r\n",
       "L 245.44375 136.791448 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 50.14375 143.1 \r\n",
       "L 50.14375 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 245.44375 143.1 \r\n",
       "L 245.44375 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 50.14375 143.1 \r\n",
       "L 245.44375 143.1 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 50.14375 7.2 \r\n",
       "L 245.44375 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"legend_1\">\r\n",
       "    <g id=\"patch_7\">\r\n",
       "     <path d=\"M 183.16875 29.878125 \r\n",
       "L 238.44375 29.878125 \r\n",
       "Q 240.44375 29.878125 240.44375 27.878125 \r\n",
       "L 240.44375 14.2 \r\n",
       "Q 240.44375 12.2 238.44375 12.2 \r\n",
       "L 183.16875 12.2 \r\n",
       "Q 181.16875 12.2 181.16875 14.2 \r\n",
       "L 181.16875 27.878125 \r\n",
       "Q 181.16875 29.878125 183.16875 29.878125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_22\">\r\n",
       "     <path d=\"M 185.16875 20.298437 \r\n",
       "L 205.16875 20.298437 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_23\"/>\r\n",
       "    <g id=\"text_13\">\r\n",
       "     <!-- train -->\r\n",
       "     <g transform=\"translate(213.16875 23.798437)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 34.28125 27.484375 \r\n",
       "Q 23.390625 27.484375 19.1875 25 \r\n",
       "Q 14.984375 22.515625 14.984375 16.5 \r\n",
       "Q 14.984375 11.71875 18.140625 8.90625 \r\n",
       "Q 21.296875 6.109375 26.703125 6.109375 \r\n",
       "Q 34.1875 6.109375 38.703125 11.40625 \r\n",
       "Q 43.21875 16.703125 43.21875 25.484375 \r\n",
       "L 43.21875 27.484375 \r\n",
       "z\r\n",
       "M 52.203125 31.203125 \r\n",
       "L 52.203125 0 \r\n",
       "L 43.21875 0 \r\n",
       "L 43.21875 8.296875 \r\n",
       "Q 40.140625 3.328125 35.546875 0.953125 \r\n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \r\n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \r\n",
       "Q 6 8.015625 6 15.921875 \r\n",
       "Q 6 25.140625 12.171875 29.828125 \r\n",
       "Q 18.359375 34.515625 30.609375 34.515625 \r\n",
       "L 43.21875 34.515625 \r\n",
       "L 43.21875 35.40625 \r\n",
       "Q 43.21875 41.609375 39.140625 45 \r\n",
       "Q 35.0625 48.390625 27.6875 48.390625 \r\n",
       "Q 23 48.390625 18.546875 47.265625 \r\n",
       "Q 14.109375 46.140625 10.015625 43.890625 \r\n",
       "L 10.015625 52.203125 \r\n",
       "Q 14.9375 54.109375 19.578125 55.046875 \r\n",
       "Q 24.21875 56 28.609375 56 \r\n",
       "Q 40.484375 56 46.34375 49.84375 \r\n",
       "Q 52.203125 43.703125 52.203125 31.203125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-97\"/>\r\n",
       "       <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-110\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"pdc7cf36ab0\">\r\n",
       "   <rect height=\"135.9\" width=\"195.3\" x=\"50.14375\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time \n",
    "# around 1:25 minutes with gpu\n",
    "\n",
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's check the results to use a random sampling iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# around 1:25 minutes with gpu\n",
    "\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(),\n",
    "          use_random_iter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While implementing the above RNN model from scratch is instructive, it is not convenient. In the next section we will see how to improve significantly on the current model and how to make it faster and easier to implement.\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "* Sequence models need state initialization for training.\n",
    "* Between sequential models you need to ensure to detach the gradients, to ensure that the automatic differentiation does not propagate effects beyond the current sample.\n",
    "* A simple RNN language model consists of an encoder, an RNN model, and a decoder.\n",
    "* Gradient clipping prevents gradient explosion (but it cannot fix vanishing gradients).\n",
    "* Perplexity calibrates model performance across different sequence length. It is the exponentiated average of the cross-entropy loss.\n",
    "* Sequential partitioning typically leads to better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Example.  Return to Slides\n",
    "\n",
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)\n",
    "\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#NLP2-Lecture-1-Support-Notebook\">\n",
    "        <span class=\"toc-item-num\">&nbsp;&nbsp;</span>\n",
    "        Go to TOP\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/d2l-ai/d2l-en@v0.16.0\n",
      "  Cloning https://github.com/d2l-ai/d2l-en (to revision v0.16.0) to c:\\users\\callmepc\\appdata\\local\\temp\\pip-req-build-blhiiu5h\n",
      "Requirement already satisfied (use --upgrade to upgrade): d2l==0.16.0 from git+https://github.com/d2l-ai/d2l-en@v0.16.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: jupyter in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from d2l==0.16.0) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from d2l==0.16.0) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from d2l==0.16.0) (3.3.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from d2l==0.16.0) (1.2.2)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter->d2l==0.16.0) (6.1.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter->d2l==0.16.0) (6.0.3)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter->d2l==0.16.0) (4.6.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter->d2l==0.16.0) (5.1.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter->d2l==0.16.0) (7.5.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter->d2l==0.16.0) (5.6.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from matplotlib->d2l==0.16.0) (7.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from matplotlib->d2l==0.16.0) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from matplotlib->d2l==0.16.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from matplotlib->d2l==0.16.0) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from matplotlib->d2l==0.16.0) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from pandas->d2l==0.16.0) (2019.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->d2l==0.16.0) (7.12.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->d2l==0.16.0) (2.5.2)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->d2l==0.16.0) (5.3.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->d2l==0.16.0) (3.0.3)\n",
      "Requirement already satisfied: nbformat in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (5.0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (4.6.1)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (0.8.3)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (4.3.3)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (6.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (18.1.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (0.7.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (0.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from notebook->jupyter->d2l==0.16.0) (2.11.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->d2l==0.16.0) (3.5.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l==0.16.0) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l==0.16.0) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l==0.16.0) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l==0.16.0) (0.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l==0.16.0) (0.4.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->d2l==0.16.0) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\callmepc\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.1->matplotlib->d2l==0.16.0) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->d2l==0.16.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\callmepc\\appdata\\roaming\\python\\python37\\site-packages (from ipython->jupyter-console->jupyter->d2l==0.16.0) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->d2l==0.16.0) (4.4.1)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->d2l==0.16.0) (0.14.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->d2l==0.16.0) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->d2l==0.16.0) (0.7.5)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jupyter-client->jupyter-console->jupyter->d2l==0.16.0) (227)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l==0.16.0) (0.1.8)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from nbformat->notebook->jupyter->d2l==0.16.0) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jinja2->notebook->jupyter->d2l==0.16.0) (1.1.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->d2l==0.16.0) (0.5.1)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->jupyter-console->jupyter->d2l==0.16.0) (0.5.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter->d2l==0.16.0) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter->d2l==0.16.0) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter->d2l==0.16.0) (19.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\callmepc\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter->d2l==0.16.0) (2.2.0)\n",
      "Building wheels for collected packages: d2l\n",
      "  Building wheel for d2l (setup.py): started\n",
      "  Building wheel for d2l (setup.py): finished with status 'done'\n",
      "  Created wheel for d2l: filename=d2l-0.16.0-py3-none-any.whl size=76190 sha256=103e0a4fd6975397228b717a89e3100010df9968940a79b351accd5ebd4c30d5\n",
      "  Stored in directory: C:\\Users\\callmepc\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-euyave3i\\wheels\\28\\6d\\74\\95b8cb4607422afd57adabc8d7ee8c7e9af4031692638edae4\n",
      "Successfully built d2l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/d2l-ai/d2l-en 'C:\\Users\\callmepc\\AppData\\Local\\Temp\\pip-req-build-blhiiu5h'\n",
      "  warning: the following paths have collided (e.g. case-sensitive paths\n",
      "  on a case-insensitive filesystem) and only one from the same\n",
      "  colliding group is in the working tree:\n",
      "\n",
      "    'static/frontpage/_images/logos/Lancaster-University.png'\n",
      "    'static/frontpage/_images/logos/lancaster-university.png'\n",
      "    'static/frontpage/_images/logos/Make-School.png'\n",
      "    'static/frontpage/_images/logos/make-school.png'\n",
      "    'static/frontpage/_images/logos/Pakuan-University.png'\n",
      "    'static/frontpage/_images/logos/pakuan-university.png'\n",
      "    'static/frontpage/_images/logos/Universidad-Nacional-Agraria-La-Molina.png'\n",
      "    'static/frontpage/_images/logos/universidad-nacional-agraria-la-molina.png'\n",
      "    'static/frontpage/_images/logos/University-of-Waterloo.png'\n",
      "    'static/frontpage/_images/logos/university-of-waterloo.png'\n",
      "  Running command git checkout -q d98c8865ab6cc191a57911d4399b8607bee81f49\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/d2l-ai/d2l-en@v0.16.0\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_mlp():\n",
    "    net.append(nn.Dropout(0.2))\n",
    "    net.append(nn.Linear(num_inputs, num_hiddens))\n",
    "    net.append(nn.ReLU())\n",
    "    if flatten:\n",
    "        net.append(nn.Flatten(start_dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(num_inputs, num_hiddens, flatten):\n",
    "    net = []\n",
    "    block_mlp()\n",
    "    block_mlp()\n",
    "    \n",
    "    return nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attend(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, **kwargs):\n",
    "        super(Attend, self).__init__(**kwargs)\n",
    "        self.f = mlp(num_inputs, num_hiddens, flatten=False)\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        # Shape of `A`/`B`: (`batch_size`, no. of words in sequence A/B,\n",
    "        # `embed_size`)\n",
    "        # Shape of `f_A`/`f_B`: (`batch_size`, no. of words in sequence A/B,\n",
    "        # `num_hiddens`)\n",
    "        f_A = self.f(A)\n",
    "        f_B = self.f(B)\n",
    "        # Shape of `e`: (`batch_size`, no. of words in sequence A,\n",
    "        # no. of words in sequence B)\n",
    "        e = torch.bmm(f_A, f_B.permute(0, 2, 1))\n",
    "        # Shape of `beta`: (`batch_size`, no. of words in sequence A,\n",
    "        # `embed_size`), where sequence B is softly aligned with each word\n",
    "        # (axis 1 of `beta`) in sequence A\n",
    "        beta = torch.bmm(F.softmax(e, dim=-1), B)\n",
    "        # Shape of `alpha`: (`batch_size`, no. of words in sequence B,\n",
    "        # `embed_size`), where sequence A is softly aligned with each word\n",
    "        # (axis 1 of `alpha`) in sequence B\n",
    "        alpha = torch.bmm(F.softmax(e.permute(0, 2, 1), dim=-1), A)\n",
    "        return beta, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compare(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, **kwargs):\n",
    "        super(Compare, self).__init__(**kwargs)\n",
    "        self.g = mlp(num_inputs, num_hiddens, flatten=False)\n",
    "\n",
    "    def forward(self, A, B, beta, alpha):\n",
    "        V_A = self.g(torch.cat([A, beta], dim=2))\n",
    "        V_B = self.g(torch.cat([B, alpha], dim=2))\n",
    "        return V_A, V_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregate(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, **kwargs):\n",
    "        super(Aggregate, self).__init__(**kwargs)\n",
    "        self.h = mlp(num_inputs, num_hiddens, flatten=True)\n",
    "        self.linear = nn.Linear(num_hiddens, num_outputs)\n",
    "\n",
    "    def forward(self, V_A, V_B):\n",
    "        # Sum up both sets of comparison vectors\n",
    "        V_A = V_A.sum(dim=1)\n",
    "        V_B = V_B.sum(dim=1)\n",
    "        # Feed the concatenation of both summarization results into an MLP\n",
    "        Y_hat = self.linear(self.h(torch.cat([V_A, V_B], dim=1)))\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposableAttention(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, num_hiddens, num_inputs_attend=100,\n",
    "                 num_inputs_compare=200, num_inputs_agg=400, **kwargs):\n",
    "        super(DecomposableAttention, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        self.attend = Attend(num_inputs_attend, num_hiddens)\n",
    "        self.compare = Compare(num_inputs_compare, num_hiddens)\n",
    "        # There are 3 possible outputs: entailment, contradiction, and neutral\n",
    "        self.aggregate = Aggregate(num_inputs_agg, num_hiddens, num_outputs=3)\n",
    "\n",
    "    def forward(self, X):\n",
    "        premises, hypotheses = X\n",
    "        A = self.embedding(premises)\n",
    "        B = self.embedding(hypotheses)\n",
    "        beta, alpha = self.attend(A, B)\n",
    "        V_A, V_B = self.compare(A, B, beta, alpha)\n",
    "        Y_hat = self.aggregate(V_A, V_B)\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '..\\\\data\\\\snli_1.0\\\\Icon\\r'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36mload_data_snli\u001b[1;34m(batch_size, num_steps)\u001b[0m\n\u001b[0;32m   2565\u001b[0m     \u001b[1;34m\"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2566\u001b[0m     \u001b[0mnum_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataloader_workers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2567\u001b[1;33m     \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SNLI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2568\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_snli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2569\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_snli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36mdownload_extract\u001b[1;34m(name, folder)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Only zip/tar files can be extracted.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1636\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m              \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '..\\\\data\\\\snli_1.0\\\\Icon\\r'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# around 1:01 minutes with gpu\n",
    "batch_size, num_steps = 256, 50\n",
    "train_iter, test_iter, vocab = d2l.load_data_snli(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# around 0:23 minutes with gpu\n",
    "embed_size, num_hiddens, devices = 100, 200, d2l.try_all_gpus()\n",
    "net = DecomposableAttention(vocab, embed_size, num_hiddens)\n",
    "glove_embedding = d2l.TokenEmbedding('glove.6b.100d')\n",
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "net.embedding.weight.data.copy_(embeds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# around 6:01 minutes with gpu\n",
    "lr, num_epochs = 0.001, 4\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)\n",
    "# net.export(\"lenet\", epoch=1) # if saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model saved previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_snli(net, vocab, premise, hypothesis):\n",
    "    net.eval()\n",
    "    premise = torch.tensor(vocab[premise], device=d2l.try_gpu())\n",
    "    hypothesis = torch.tensor(vocab[hypothesis], device=d2l.try_gpu())\n",
    "    label = torch.argmax(net([premise.reshape((1, -1)),\n",
    "                           hypothesis.reshape((1, -1))]), dim=1)\n",
    "    return 'entailment' if label == 0 else 'contradiction' if label == 1 \\\n",
    "            else 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_snli(net, ['he', 'is', 'good', '.'], ['he', 'is', 'bad', '.'])\n",
    "predict_snli(net, vocab, ['he', 'is', 'good', '.'], ['he', 'is', 'bad', '.'])\n",
    "#predict_snli(deserialized_net, ['he', 'is', 'good', '.'], ['he', 'is', 'bad', '.']) # to use saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Example.  Return to Slides\n",
    "\n",
    "![MLU Logo](https://drive.corp.amazon.com/view/bwernes@/MLU_Logo.png?download=true)\n",
    "\n",
    "<div class=\"lev1\">\n",
    "    <a href=\"#NLP2-Lecture-1-Support-Notebook\">\n",
    "        <span class=\"toc-item-num\">&nbsp;&nbsp;</span>\n",
    "        Go to TOP\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
